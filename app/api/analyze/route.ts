// app/api/analyze/route.ts
import { NextResponse } from "next/server";
import { ChatGoogleGenerativeAI } from "@langchain/google-genai";
import { tavily } from "@tavily/core";
import { StartupMCTS, type Stats } from "@/lib/mcts";
import { JsonOutputParser } from "@langchain/core/output_parsers";
import { PromptTemplate } from "@langchain/core/prompts";

export const dynamic = "force-dynamic";
export const maxDuration = 60;

// ------------------------------
// 1) Gemini ëª¨ë¸ ëª©ë¡(ListModels) ê¸°ë°˜ Fallback
// ------------------------------
type ModelInfo = {
  name?: string;
  supportedGenerationMethods?: string[];
};

const MODEL_CACHE_TTL_MS = 10 * 60 * 1000;

declare global {
  // eslint-disable-next-line no-var
  var __GEMINI_MODEL_CACHE__: { ts: number; models: string[] } | undefined;
}

function extractErrMsg(e: any): string {
  const parts: string[] = [];
  if (e?.message) parts.push(String(e.message));
  if (e?.cause?.message && e.cause.message !== e.message) parts.push(`cause: ${e.cause.message}`);
  return parts.join(" | ") || String(e);
}

async function fetchAvailableModels(apiKey: string): Promise<string[]> {
  const cache = globalThis.__GEMINI_MODEL_CACHE__;
  if (cache && Date.now() - cache.ts < MODEL_CACHE_TTL_MS && cache.models.length) {
    return cache.models;
  }

  const url = `https://generativelanguage.googleapis.com/v1beta/models?key=${encodeURIComponent(apiKey)}`;
  const res = await fetch(url, {
    method: "GET",
    headers: { "Content-Type": "application/json" },
    cache: "no-store",
  });

  if (!res.ok) {
    throw new Error(`ListModels ì‹¤íŒ¨: HTTP ${res.status} ${res.statusText}`);
  }

  const data = (await res.json()) as { models?: ModelInfo[] };

  const models =
    (data.models ?? [])
      .filter((m) => (m.supportedGenerationMethods ?? []).includes("generateContent"))
      .map((m) => (m.name ?? "").replace(/^models\//, ""))
      .filter(Boolean) ?? [];

  globalThis.__GEMINI_MODEL_CACHE__ = { ts: Date.now(), models };
  return models;
}

function buildFallbackModels(available: string[]): string[] {
  const preferredPatterns = [
    "gemini-2.0-flash",
    "gemini-2.0-flash-exp",
    "gemini-1.5-pro",
    "gemini-1.5-flash",
    "gemini-1.0-pro",
  ];

  const picked: string[] = [];
  const availSet = new Set(available);

  const pickOne = (pattern: string): string | null => {
    if (availSet.has(pattern)) return pattern;
    const starts = available.find((m) => m.startsWith(pattern));
    return starts ?? null;
  };

  for (const p of preferredPatterns) {
    const m = pickOne(p);
    if (m && !picked.includes(m)) picked.push(m);
  }

  return picked.length ? picked : available.slice(0, 3);
}

async function generateWithFallback<T>(
  apiKey: string,
  prompt: PromptTemplate,
  inputVariables: Record<string, any>,
  parser?: JsonOutputParser<T>
): Promise<T | any> {
  const available = await fetchAvailableModels(apiKey);
  const models = buildFallbackModels(available);

  let lastError: any = null;

  for (const modelName of models) {
    try {
      const llm = new ChatGoogleGenerativeAI({
        model: modelName,
        apiKey,
        temperature: 0.35,
      });

      const chain = parser ? prompt.pipe(llm).pipe(parser) : prompt.pipe(llm);
      return await chain.invoke(inputVariables);
    } catch (e: any) {
      console.warn(`âš ï¸ ëª¨ë¸ ì‹¤íŒ¨: ${modelName} -> ${extractErrMsg(e)}`);
      lastError = e;
    }
  }

  throw new Error(`ëª¨ë“  Gemini ëª¨ë¸ í˜¸ì¶œ ì‹¤íŒ¨. last=${extractErrMsg(lastError)}`);
}

function getContent(res: any): string {
  if (typeof res === "string") return res;
  if (res?.content != null) return String(res.content);
  return JSON.stringify(res);
}

// ------------------------------
// 2) API í•¸ë“¤ëŸ¬
// ------------------------------
export async function POST(req: Request) {
  try {
    const tavilyKey = process.env.TAVILY_API_KEY;
    const googleKey = process.env.GOOGLE_API_KEY;

    if (!tavilyKey || !googleKey) {
      return NextResponse.json(
        { success: false, error: "API í‚¤ê°€ ì—†ìŠµë‹ˆë‹¤. Vercel í™˜ê²½ë³€ìˆ˜ë¥¼ í™•ì¸í•´ì£¼ì„¸ìš”." },
        { status: 500 }
      );
    }

    const body = await req.json().catch(() => null);
    if (!body?.productInfo?.name) {
      return NextResponse.json({ success: false, error: "í•„ìˆ˜ ì •ë³´ê°€ ëˆ„ë½ë˜ì—ˆìŠµë‹ˆë‹¤." }, { status: 400 });
    }

    const language = body.language === "en" ? "en" : "ko";
    const { sellerInfo, buyerInfo, productInfo, founderTraits } = body;

    console.log("ğŸ”¥ ë¶„ì„ ì‹œì‘:", productInfo?.name);

    // --- Tavily ê²€ìƒ‰ (ìœ ì‚¬ ì‚¬ë¡€/ê²½ìŸì‚¬/ë¬¸ì œì ) ---
    const tvly = tavily({ apiKey: tavilyKey });
    let marketData = "ì‹œì¥ ë°ì´í„° ì—†ìŒ";
    let pastCases: any[] = [];

    try {
      const searchResult = await tvly.search(`${productInfo.name} ì‹¤íŒ¨ ì‚¬ë¡€ ê²½ìŸì‚¬ ë¬¸ì œì  ë¶ˆë§Œ ë¦¬ë·°`, {
        searchDepth: "advanced",
        maxResults: 5,
      });

      marketData = (searchResult.results ?? [])
        .map((r: any) => `- ${r.title}: ${String(r.content ?? "").slice(0, 350)}...`)
        .join("\n");

      pastCases = (searchResult.results ?? []).map((r: any) => ({
        title: r.title,
        url: r.url,
        content: r.content,
      }));
    } catch (e: any) {
      console.error("Tavily ê²€ìƒ‰ ì‹¤íŒ¨(ë¬´ì‹œ):", e?.message);
    }

    // --- Stats ---
    const statsParser = new JsonOutputParser<Partial<Stats>>();
    const statsPrompt = PromptTemplate.fromTemplate(
      `ë„ˆëŠ” ëƒ‰ì†Œì ì¸ ìŠ¤íƒ€íŠ¸ì—… ê²€ì¦ê´€ì´ë‹¤.
ì¶œë ¥ ì–¸ì–´ëŠ” {language}ì— ë§ì¶°ë¼. (ko=í•œêµ­ì–´, en=English)
ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(**, *, #, \`\`\`)ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , í‰ë¬¸ìœ¼ë¡œë§Œ ì‘ì„±í•˜ë¼.

ì…ë ¥ ì •ë³´:
- íŒë§¤ì: {sellerInfo}
- íƒ€ê²Ÿ: {buyerInfo}
- ì•„ì´í…œ: {productInfo}
- ì°½ì—…ì íŠ¹ì„±(10ì  ë§Œì ): {founderTraits}

ì‹œì¥ ë°ì´í„°:
{marketData}

{format_instructions}

JSON í‚¤: product, team, strategy, marketing, consumer_needs
ëª¨ë“  ê°’ì€ 0~100 ì •ìˆ˜ë¡œ ì¶œë ¥.`
    );

    const rawStats = await generateWithFallback(
      googleKey,
      statsPrompt,
      {
        language,
        sellerInfo,
        buyerInfo,
        productInfo: JSON.stringify(productInfo),
        founderTraits: JSON.stringify(founderTraits),
        marketData,
        format_instructions: statsParser.getFormatInstructions(),
      },
      statsParser
    );

    const safeStats: Stats = {
      product: Number((rawStats as any)?.product) || 0,
      team: Number((rawStats as any)?.team) || 0,
      strategy: Number((rawStats as any)?.strategy) || 0,
      marketing: Number((rawStats as any)?.marketing) || 0,
      consumer_needs: Number((rawStats as any)?.consumer_needs) || 0,
    };

    // --- MCTS ---
    const mcts = new StartupMCTS(1500);
    const simulation = mcts.run(safeStats);

    // --- Report (ìœ íŠœë¸Œ ì¿¼ë¦¬ + í‚¤ì›Œë“œ í¬í•¨, ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€) ---
    const reportParser = new JsonOutputParser<any>();
    const reportPrompt = PromptTemplate.fromTemplate(
      `ë„ˆëŠ” ëƒ‰ì†Œì ì¸ VCë‹¤. ì•„ë˜ ì •ë³´ë¥¼ ë°”íƒ•ìœ¼ë¡œ "ë¶€ê²€ ë¦¬í¬íŠ¸"ë¥¼ JSONìœ¼ë¡œ ì‘ì„±í•˜ë¼.
ì¶œë ¥ ì–¸ì–´ëŠ” {language}ì— ë§ì¶°ë¼. (ko=í•œêµ­ì–´, en=English)
ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(**, *, #, \`\`\`)ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , í‰ë¬¸ìœ¼ë¡œë§Œ ì‘ì„±í•˜ë¼.
íŠ¹íˆ êµµê²Œ(**) ê°™ì€ í‘œì‹œ ì ˆëŒ€ ê¸ˆì§€.

ìŠ¤íƒ¯: {stats}
ê°€ì¥ ë§ì´ ì£½ì€ êµ¬ê°„: {bottleneck}
ì‹œì¥ë°ì´í„°: {marketData}

{format_instructions}

JSON í‚¤:
- death_cause (ì§§ê²Œ í•œ ì¤„)
- autopsy_report (ë¬¸ë‹¨/ëª©ë¡ ê°€ëŠ¥, í•˜ì§€ë§Œ ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€)
- action_plan (ëª©ë¡ ê°€ëŠ¥, í•˜ì§€ë§Œ ë§ˆí¬ë‹¤ìš´ ê¸ˆì§€)
- needs_analysis (ì§§ê²Œ 3~6ë¬¸ì¥)
- youtube_queries (ë¬¸ìì—´ ë°°ì—´ 3ê°œ, ìœ íŠœë¸Œ ê²€ìƒ‰ì–´ í˜•íƒœ)
- keywords (ë¬¸ìì—´ ë°°ì—´ 10ê°œ, í•œ ë‹¨ì–´/ì§§ì€ êµ¬)
`
    );

    // --- Debate (ì¢Œë‹´íšŒ í…ìŠ¤íŠ¸, ë§ˆì§€ë§‰ì— í‚¤ì›Œë“œ ë¼ì¸) ---
    const debatePrompt = PromptTemplate.fromTemplate(
      `ì•„ë˜ ì •ë³´ë¥¼ ë³´ê³  3ëª…ì˜ ì „ë¬¸ê°€ê°€ ë…ì„¤ ì¢Œë‹´íšŒë¥¼ ì—´ì–´ë¼. (í•œêµ­ì–´/ì˜ì–´ëŠ” languageì— ë§ì¶°ë¼)
language: {language}
ì ˆëŒ€ ë§ˆí¬ë‹¤ìš´ ë¬¸ë²•(**, *, #, \`\`\`)ì„ ì‚¬ìš©í•˜ì§€ ë§ê³ , í‰ë¬¸ ëŒ€í™”ì²´ë¡œë§Œ ì‘ì„±í•˜ë¼.

1) ë§ˆí¬êµ¬ VC (ëƒ‰ì†Œì )
2) í…Œí—¤ë€ë¡œ ì°½ì—…ê°€ (í˜„ì‹¤ì )
3) ê¹Œì¹ í•œ ì–¼ë¦¬ì–´ë‹µí„° (ë¶ˆë§Œ ë§ìŒ)

ì•„ì´í…œ: {item}
ìŠ¤íƒ¯: {stats}

ë§ˆì§€ë§‰ ì¤„ì€ ì•„ë˜ í˜•ì‹:
ê²°ë¡ : í•œ ì¤„
í‚¤ì›Œë“œ: ë‹¨ì–´1, ë‹¨ì–´2, ë‹¨ì–´3, ... (10ê°œ)`
    );

    const [report, debateRes] = await Promise.all([
      generateWithFallback(
        googleKey,
        reportPrompt,
        {
          language,
          stats: JSON.stringify(safeStats),
          bottleneck: (simulation as any)?.bottleneck ?? (simulation as any)?.bottleneck_stage ?? "",
          marketData,
          format_instructions: reportParser.getFormatInstructions(),
        },
        reportParser
      ),
      generateWithFallback(googleKey, debatePrompt, {
        language,
        item: JSON.stringify(productInfo),
        stats: JSON.stringify(safeStats),
      }),
    ]);

    return NextResponse.json({
      success: true,
      stats: safeStats,
      simulation,
      report,
      debate: getContent(debateRes),
      pastCases,
    });
  } catch (error: any) {
    console.error("Server Error:", extractErrMsg(error));
    return NextResponse.json({ success: false, error: extractErrMsg(error) }, { status: 500 });
  }
}
